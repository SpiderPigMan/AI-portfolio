import os
import shutil
from dotenv import load_dotenv
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import CharacterTextSplitter
# IMPORTANTE: Nuevos imports para OpenAI
from langchain_openai import OpenAIEmbeddings
# from langchain_huggingface import HuggingFaceEmbeddings -- No se usa en esta versi√≥n por falta de RAM en el servidor, se opta por OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

# 1. Cargar configuraci√≥n
load_dotenv()

def create_vector_db():
    print("--- Iniciando proceso de INGESTA ---")
    
    # 2. Cargar documentos (.md) desde la carpeta 'data'
    loader = DirectoryLoader(
        './data', 
        glob="./*.md", 
        loader_cls=TextLoader,
        loader_kwargs={'encoding': 'utf-8'}
    )
    docs = loader.load()
    print(f"‚úÖ Documentos encontrados: {len(docs)}")

    # 3. Fragmentaci√≥n (Chunking)
    text_splitter = CharacterTextSplitter(chunk_size=4000, chunk_overlap=500)
    chunks = text_splitter.split_documents(docs)
    print(f"‚úÖ Texto dividido en {len(chunks)} fragmentos.")

    # 4. CONFIGURACI√ìN DE EMBEDDINGS (Toggle)
    # --- OPCI√ìN A: OpenAI (Recomendado para Producci√≥n/Render) ---
    print("‚è≥ Generando vectores con OpenAI (Dimensi√≥n 1536)...")
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    # --- OPCI√ìN B: HuggingFace (Local/Gratis - Dimensi√≥n 384) ---
    # Para volver a este modelo, comenta la l√≠nea de OpenAI arriba y descomenta estas:
    # print("‚è≥ Generando vectores localmente con HuggingFace (Dimensi√≥n 384)...")
    # embeddings = HuggingFaceEmbeddings(model_name="paraphrase-multilingual-MiniLM-L12-v2")
    
    # 5. Gesti√≥n de la base de datos (ChromaDB)
    persist_dir = "./chroma_db"
    
    # Limpieza autom√°tica para evitar errores de dimensi√≥n
    if os.path.exists(persist_dir):
        print(f"üßπ Eliminando base de datos antigua en {persist_dir} para evitar conflictos de dimensiones...")
        shutil.rmtree(persist_dir)

    vector_db = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        persist_directory=persist_dir,
        collection_metadata={"hnsw:space": "cosine"}
    )
    
    print("--- üöÄ ¬°√âXITO! Nueva base de datos lista con dimensiones de OpenAI ---")

if __name__ == "__main__":
    create_vector_db()